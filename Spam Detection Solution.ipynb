{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the dataset\n",
    "\n",
    ">** Instructions: **\n",
    "* Import the dataset into a pandas dataframe using the read_table method. Because this is a tab separated dataset we will be using '\\t' as the value for the 'sep' argument which specifies this format. \n",
    "* Also, rename the column names by specifying a list ['label, 'sms_message'] to the 'names' argument of read_table().\n",
    "* Print the first five values of the dataframe with the new column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                                sms\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading de tab separete values file with padas, converting in a data frame\n",
    "import pandas as pd\n",
    "sms_df = pd.read_table('smsspamcollection/SMSSpamCollection',\n",
    "                   sep='\\t', \n",
    "                   header=None, \n",
    "                   names=['label', 'sms'])\n",
    "sms_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    ">**Instructions: **\n",
    "* Convert the values in the 'label' colum to numerical values using map method as follows:\n",
    "{'ham':0, 'spam':1} This maps the 'ham' value to 0 and the 'spam' value to 1.\n",
    "* Also, to get an idea of the size of the dataset we are dealing with, print out number of rows and columns using \n",
    "'shape'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      label                                                sms\n",
      "0         0  Go until jurong point, crazy.. Available only ...\n",
      "1         0                      Ok lar... Joking wif u oni...\n",
      "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3         0  U dun say so early hor... U c already then say...\n",
      "4         0  Nah I don't think he goes to usf, he lives aro...\n",
      "5         1  FreeMsg Hey there darling it's been 3 week's n...\n",
      "6         0  Even my brother is not like to speak with me. ...\n",
      "7         0  As per your request 'Melle Melle (Oru Minnamin...\n",
      "8         1  WINNER!! As a valued network customer you have...\n",
      "9         1  Had your mobile 11 months or more? U R entitle...\n",
      "10        0  I'm gonna be home soon and i don't want to tal...\n",
      "11        1  SIX chances to win CASH! From 100 to 20,000 po...\n",
      "12        1  URGENT! You have won a 1 week FREE membership ...\n",
      "13        0  I've been searching for the right words to tha...\n",
      "14        0                I HAVE A DATE ON SUNDAY WITH WILL!!\n",
      "15        1  XXXMobileMovieClub: To use your credit, click ...\n",
      "16        0                         Oh k...i'm watching here:)\n",
      "17        0  Eh u remember how 2 spell his name... Yes i di...\n",
      "18        0  Fine if thats the way u feel. Thats the way ...\n",
      "19        1  England v Macedonia - dont miss the goals/team...\n",
      "20        0          Is that seriously how you spell his name?\n",
      "21        0    I‘m going to try for 2 months ha ha only joking\n",
      "22        0  So ü pay first lar... Then when is da stock co...\n",
      "23        0  Aft i finish my lunch then i go str down lor. ...\n",
      "24        0  Ffffffffff. Alright no way I can meet up with ...\n",
      "25        0  Just forced myself to eat a slice. I'm really ...\n",
      "26        0                     Lol your always so convincing.\n",
      "27        0  Did you catch the bus ? Are you frying an egg ...\n",
      "28        0  I'm back &amp; we're packing the car now, I'll...\n",
      "29        0  Ahhh. Work. I vaguely remember that! What does...\n",
      "...     ...                                                ...\n",
      "5542      0           Armand says get your ass over to epsilon\n",
      "5543      0             U still havent got urself a jacket ah?\n",
      "5544      0  I'm taking derek &amp; taylor to walmart, if I...\n",
      "5545      0      Hi its in durban are you still on this number\n",
      "5546      0         Ic. There are a lotta childporn cars then.\n",
      "5547      1  Had your contract mobile 11 Mnths? Latest Moto...\n",
      "5548      0                 No, I was trying it all weekend ;V\n",
      "5549      0  You know, wot people wear. T shirts, jumpers, ...\n",
      "5550      0        Cool, what time you think you can get here?\n",
      "5551      0  Wen did you get so spiritual and deep. That's ...\n",
      "5552      0  Have a safe trip to Nigeria. Wish you happines...\n",
      "5553      0                        Hahaha..use your brain dear\n",
      "5554      0  Well keep in mind I've only got enough gas for...\n",
      "5555      0  Yeh. Indians was nice. Tho it did kane me off ...\n",
      "5556      0  Yes i have. So that's why u texted. Pshew...mi...\n",
      "5557      0  No. I meant the calculation is the same. That ...\n",
      "5558      0                             Sorry, I'll call later\n",
      "5559      0  if you aren't here in the next  &lt;#&gt;  hou...\n",
      "5560      0                  Anything lor. Juz both of us lor.\n",
      "5561      0  Get me out of this dump heap. My mom decided t...\n",
      "5562      0  Ok lor... Sony ericsson salesman... I ask shuh...\n",
      "5563      0                                Ard 6 like dat lor.\n",
      "5564      0  Why don't you wait 'til at least wednesday to ...\n",
      "5565      0                                       Huh y lei...\n",
      "5566      1  REMINDER FROM O2: To get 2.50 pounds free call...\n",
      "5567      1  This is the 2nd time we have tried 2 contact u...\n",
      "5568      0               Will ü b going to esplanade fr home?\n",
      "5569      0  Pity, * was in mood for that. So...any other s...\n",
      "5570      0  The guy did some bitching but I acted like i'd...\n",
      "5571      0                         Rofl. Its true to its name\n",
      "\n",
      "[5572 rows x 2 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                                sms\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_label_column = sms_df.label.map({'ham':0, 'spam':1})\n",
    "sms_df['label'] = binary_label_column\n",
    "print(sms_df)\n",
    "sms_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Spliting Dataset into Training and Testing\n",
    "\n",
    ">**Instructions:**\n",
    "Split the dataset into a training and testing set by using the train_test_split method in sklearn. Split the data\n",
    "using the following variables:\n",
    "* `X_train` is our training data for the 'sms_message' column.\n",
    "* `y_train` is our training data for the 'label' column\n",
    "* `X_test` is our testing data for the 'sms_message' column.\n",
    "* `y_test` is our testing data for the 'label' column\n",
    "Print out the number of rows we have in each our training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# rows in full dataset:  5572\n",
      "# rows in traning dataset:  4179\n",
      "# rows in test dataset:  1393\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(sms_df['sms'],\n",
    "                                                   sms_df['label'],\n",
    "                                                   random_state=1)\n",
    "print('# rows in full dataset: ', str(sms_df.shape[0]))\n",
    "print('# rows in traning dataset: ', str(x_train.shape[0]))\n",
    "print('# rows in test dataset: ', str(x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying Bag of Words processing to our dataset\n",
    "\n",
    ">**Instructions:**\n",
    "* Firstly, we have to fit our training data (`X_train`) into `CountVectorizer()` and return the matrix.\n",
    "* Secondly, we have to transform our testing data (`X_test`) to return the matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vector = CountVectorizer()\n",
    "training_data = count_vector.fit_transform(x_train)\n",
    "testing_data = count_vector.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes implementation\n",
    "\n",
    ">**Instructions:**\n",
    "* We have loaded the training data into the variable 'training_data' and the testing data into the \n",
    "variable 'testing_data'.\n",
    "* Import the MultinomialNB classifier and fit the training data into the classifier using fit(). Name your classifier\n",
    "'naive_bayes'. You will be training the classifier using 'training_data' and y_train' from our split earlier. \n",
    "* Now that our algorithm has been trained using the training data set we can now make some predictions on the test data stored in 'testing_data' using predict(). Save your predictions into the 'predictions' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(training_data, y_train)\n",
    "predictions = naive_bayes.predict(testing_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating our model\n",
    "\n",
    ">**Instructions:**\n",
    "* Compute the accuracy, precision, recall and F1 scores of your model using your test data 'y_test' and the predictions you made earlier stored in the 'predictions' variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def evaluate(y_test, predictions):\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test,predictions)\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "def show_evalution(y_test, predictions):\n",
    "    accuracy,precision,recall,f1 = evaluate(y_test,predictions)\n",
    "    print('Accuracy score: ', str(accuracy))\n",
    "    print('Precision score: ', str(precision))\n",
    "    print('Recall score: ', str(recall))\n",
    "    print('F1 score: ', str(f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.988513998564\n",
      "Precision score:  0.972067039106\n",
      "Recall score:  0.940540540541\n",
      "F1 score:  0.956043956044\n"
     ]
    }
   ],
   "source": [
    "show_evalution(y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "One of the major advantages that Naive Bayes has over other classification algorithms is its ability to handle an extremely large number of features. In our case, each word is treated as a feature and there are thousands of different words. Also, it performs well even with the presence of irrelevant features and is relatively unaffected by them. The other major advantage it has is its relative simplicity. Naive Bayes' works well right out of the box and tuning it's parameters is rarely ever necessary, except usually in cases where the distribution of the data is known. It rarely ever overfits the data. Another important advantage is that its model training and prediction times are very fast for the amount of data it can handle. All in all, Naive Bayes' really is a gem of an algorithm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
